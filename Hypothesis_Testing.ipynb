{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umC_4VY6Nt-3",
        "outputId": "f0baacf4-1fc3-4988-dcc3-850d6a11c795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              keywords        name  \\\n",
            "0.0  [{'name': 'glocations', 'value': 'iran', 'rank...  glocations   \n",
            "1.0  [{'name': 'glocations', 'value': 'iran', 'rank...     persons   \n",
            "2.0  [{'name': 'glocations', 'value': 'iran', 'rank...     subject   \n",
            "3.0  [{'name': 'glocations', 'value': 'iran', 'rank...     subject   \n",
            "4.0  [{'name': 'glocations', 'value': 'iran', 'rank...     subject   \n",
            "\n",
            "                                     value  rank major  \n",
            "0.0                                   iran   1.0     n  \n",
            "1.0                   hassani, gholam-reza   2.0     n  \n",
            "2.0  united states international relations   3.0     n  \n",
            "3.0                              forecasts   4.0     n  \n",
            "4.0                                  islam   5.0     n  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_excel('/content/Combined_Data.xlsx')\n",
        "\n",
        "# Function to convert JSON strings to dictionaries and flatten them\n",
        "def extract_json_objects(json_str):\n",
        "    try:\n",
        "        # Load the JSON content\n",
        "        json_data = json.loads(json_str.replace('\\'', '\\\"'))\n",
        "        # Flatten the JSON data\n",
        "        return pd.json_normalize(json_data)\n",
        "    except:\n",
        "        # Return None if JSON is empty or invalid\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Initialize an empty DataFrame to store the expanded JSON data\n",
        "expanded_data = pd.DataFrame()\n",
        "\n",
        "# Iterate through each row and process the JSON content\n",
        "for index, row in data.iterrows():\n",
        "    row_data = extract_json_objects(row['keywords'])\n",
        "    if not row_data.empty:\n",
        "        # Add a new column for the index to merge on\n",
        "        row_data['original_index'] = index\n",
        "        # Append to the expanded DataFrame\n",
        "        expanded_data = pd.concat([expanded_data, row_data], ignore_index=True)\n",
        "\n",
        "# Merge the expanded data with the original DataFrame\n",
        "result = pd.merge(data, expanded_data, how='left', left_index=True, right_on='original_index')\n",
        "\n",
        "# Drop the auxiliary 'original_index' column\n",
        "result.drop('original_index', axis=1, inplace=True)\n",
        "\n",
        "# Display the first few rows of the resulting DataFrame\n",
        "print(result.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mp13Xx6aSdwJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8d91c17-4096-4768-a321-2d7f1eeec1af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c09dbfc3-e76c-4493-ba9f-701db919fa3d\", \"result.csv\", 331846494)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import files  # Importing the files module\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_excel('/content/Combined_Data.xlsx')\n",
        "\n",
        "# Function to convert JSON strings to dictionaries and flatten them\n",
        "def extract_json_objects(json_str):\n",
        "    try:\n",
        "        # Load the JSON content\n",
        "        json_data = json.loads(json_str.replace('\\'', '\\\"'))\n",
        "        # Flatten the JSON data\n",
        "        return pd.json_normalize(json_data)\n",
        "    except:\n",
        "        # Return None if JSON is empty or invalid\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Initialize an empty DataFrame to store the expanded JSON data\n",
        "expanded_data = pd.DataFrame()\n",
        "\n",
        "# Iterate through each row and process the JSON content\n",
        "for index, row in data.iterrows():\n",
        "    row_data = extract_json_objects(row['keywords'])\n",
        "    if not row_data.empty:\n",
        "        # Add a new column for the index to merge on\n",
        "        row_data['original_index'] = index\n",
        "        # Append to the expanded DataFrame\n",
        "        expanded_data = pd.concat([expanded_data, row_data], ignore_index=True)\n",
        "\n",
        "# Merge the expanded data with the original DataFrame\n",
        "result = pd.merge(data, expanded_data, how='left', left_index=True, right_on='original_index')\n",
        "\n",
        "# Drop the auxiliary 'original_index' column\n",
        "result.drop('original_index', axis=1, inplace=True)\n",
        "\n",
        "# Save the resulting DataFrame as a CSV file\n",
        "result.to_csv('/content/result.csv', index=False)\n",
        "\n",
        "# Download the CSV file from Colab\n",
        "files.download('/content/result.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/result.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Add numerical features: word count and sentiment score\n",
        "data['word_count'] = data['cleaned_value_no_stopwords'].apply(lambda x: len(x.split()))\n",
        "data['sentiment_score'] = data['sentiment'].map({'positive': 1, 'neutral': 0, 'negative': -1})\n",
        "\n",
        "# Correlation analysis\n",
        "correlation_matrix = data[['word_count', 'sentiment_score']].corr()\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Hypothesis testing: compare word counts between positive and neutral sentiments\n",
        "positive_word_counts = data[data['sentiment'] == 'positive']['word_count']\n",
        "neutral_word_counts = data[data['sentiment'] == 'neutral']['word_count']\n",
        "\n",
        "# Perform t-test\n",
        "t_stat, p_value = stats.ttest_ind(positive_word_counts, neutral_word_counts, equal_var=False)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "\n",
        "# Interpret the hypothesis test\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis - Significant differences exist between the groups.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis - No significant difference between the groups.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vVxoHCoE4Le",
        "outputId": "7a06b471-fc3e-42de-dcea-536b1a2b9312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              cleaned_value_no_stopwords sentiment\n",
            "0  united states international relations   neutral\n",
            "1                              forecasts   neutral\n",
            "2                                  islam   neutral\n",
            "3  united states international relations   neutral\n",
            "4                              forecasts   neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/labeled_politically_relevant_data.csv'\n",
        "politically_relevant_data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert text data into TF-IDF features and prepare labels\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Using 1000 features for this example\n",
        "X = tfidf_vectorizer.fit_transform(politically_relevant_data['cleaned_value_no_stopwords'])\n",
        "y = politically_relevant_data['sentiment']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model on the training data\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the sentiment labels for the test data\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "# Generate a classification report to evaluate the model's performance\n",
        "classification_results = classification_report(y_test, y_pred)\n",
        "print(classification_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXuX6JCEhYe",
        "outputId": "34ddd457-757a-470c-9f43-8c18f54c8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.98      0.99      1780\n",
            "     neutral       1.00      1.00      1.00     38062\n",
            "    positive       1.00      0.98      0.99      1206\n",
            "\n",
            "    accuracy                           1.00     41048\n",
            "   macro avg       1.00      0.98      0.99     41048\n",
            "weighted avg       1.00      1.00      1.00     41048\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the dataset from the specified file path\n",
        "file_path = '/content/labeled_politically_relevant_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate numerical features: word count and sentiment score\n",
        "data['word_count'] = data['cleaned_value_no_stopwords'].apply(lambda x: len(x.split()))\n",
        "data['sentiment_score'] = data['sentiment'].map({'positive': 1, 'neutral': 0, 'negative': -1})\n",
        "\n",
        "# Perform correlation analysis between word count and sentiment score\n",
        "correlation_matrix = data[['word_count', 'sentiment_score']].corr()\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Hypothesis testing: compare word counts between positive and neutral sentiments\n",
        "positive_word_counts = data[data['sentiment'] == 'positive']['word_count']\n",
        "neutral_word_counts = data[data['sentiment'] == 'neutral']['word_count']\n",
        "\n",
        "# Conduct a t-test to compare the means of word counts in positive and neutral sentiment groups\n",
        "# Null Hypothesis (H0): There is no difference in the mean word counts between positive and neutral sentiments\n",
        "# Alternative Hypothesis (H1): There is a significant difference in the mean word counts between positive and neutral sentiments\n",
        "t_stat, p_value = stats.ttest_ind(positive_word_counts, neutral_word_counts, equal_var=False)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results of the hypothesis test\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    # Reject the null hypothesis if the p-value is less than alpha\n",
        "    print(\"Reject the null hypothesis - Significant differences exist between the groups.\")\n",
        "else:\n",
        "    # Fail to reject the null hypothesis if the p-value is greater than or equal to alpha\n",
        "    print(\"Fail to reject the null hypothesis - No significant difference between the groups.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nyX1_E8Kk9G",
        "outputId": "a10cf216-4661-4981-a740-4dc43617851e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "                 word_count  sentiment_score\n",
            "word_count         1.000000        -0.069988\n",
            "sentiment_score   -0.069988         1.000000\n",
            "T-statistic: 24.229384639246998, P-value: 3.2446094418305666e-124\n",
            "Reject the null hypothesis - Significant differences exist between the groups.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}